{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение без учителя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим простейший алгоритм обучения без учителя - кластеризацию методом к-средних (k-means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# подготовка среды\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# настройки картинок\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризацией данных будем неформально называть процедуру группировки объектов в классы так, что объекты внутри класса были близки друг к другу на основе некоторой введенной нами метрики (Евклидово расстояние, семантическая похожесть текстов, цвет картинок, и т.д.).\n",
    "\n",
    "Алгоритм работает без учителя, то есть нам необходима матрица объекты-признаки, а так же желаемое число классов.\n",
    "\n",
    "Создадим некоторый исcкуственный дата сет, в котором явно присутствуют классы объектов, но эти классы нам не известны заранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "X, y = make_blobs(n_samples=300, centers=4,\n",
    "                  random_state=0, cluster_std=0.60)\n",
    "plt.scatter(X[:, 0], X[:, 1], s=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применить k-means к этим данным значит назначить каждому объекту некоторый класс (цвет). \n",
    "Используется эффективный алгоритм максимизации ожидания *Expectation Maximization (EM)*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "est = KMeans(4)  # 4 класса\n",
    "est.fit(X)\n",
    "y_kmeans = est.predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='rainbow');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подробнее об алгоритме K-Means: Expectation Maximization\n",
    "\n",
    "1. Начинаем с случайных центров классов\n",
    "2. Повторять до сходимости:\n",
    "   A. Назначить всем точкам класс, выбирая центы классов с минимальным расстоянием\n",
    "   B. Пересчитать координату центра класса \n",
    "   \n",
    "Визуально это выглядит так: https://www.youtube.com/watch?time_continue=50&v=5I3Ei69I40s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проблемы KMeans \n",
    "\n",
    "K-means не гарантирует нахождение глобального оптимального решения. К тому же, как видно из описания, алгоритм начинается со случайной инициализации центров классов. В результате алгоритм при разных запусках находит разное решение.\n",
    "\n",
    "На практике делают несколько запусков кластеризации, затем выбирая лучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация цифр с помощью KMeans\n",
    "\n",
    "Запустим алгорит K-means на картинках. Найдем 10 классов, используя Евклидову меру в 64 мерном пространстве признаков (корень из суммы квадратов разницы яркости пикселей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "est = KMeans(n_clusters=10)\n",
    "clusters = est.fit_predict(digits.data)\n",
    "est.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем построить центры (64 значения) каждого из 10 классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 3))\n",
    "for i in range(10):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    ax.imshow(est.cluster_centers_[i].reshape((8, 8)), cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, некоторые классы вполне себе различимы.\n",
    "\n",
    "# ЗАДАНИЕ\n",
    "\n",
    "Посмотрите, что произойдет при увеличении числа классов? Какие центроиды получились?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Еще пример: KMeans для компрессии цвета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_sample_image\n",
    "china = load_sample_image(\"china.jpg\")\n",
    "plt.imshow(china)\n",
    "plt.grid(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинка хранится в 3-х мерном массиве размера ``(высота, ширина, RGB)``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "china.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в примере с цифрами, преобразуем в одномерный массив:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = (china / 255.0).reshape(-1, 3)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас 273,280 точки в 3 измерениях.\n",
    "\n",
    "Задача - сжать $256^3$ цветов в меньшее количество (например 64). По сути, мы хотим найти кластеры из N цветов и создать новое изображение, в котором цвет будет заменяться цветом центра ближайшего класса \n",
    "\n",
    "\n",
    "Для быстроты и возможности работы с большими данными, используем ``MiniBatchKMeans``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# уменьшаем до 64 цветов\n",
    "n_colors = 64\n",
    "\n",
    "X = (china / 255.0).reshape(-1, 3)\n",
    "    \n",
    "model = MiniBatchKMeans(n_colors)\n",
    "labels = model.fit_predict(X)\n",
    "colors = model.cluster_centers_\n",
    "new_image = colors[labels].reshape(china.shape)\n",
    "new_image = (255 * new_image).astype(np.uint8)\n",
    "\n",
    "# создаем и рисуем\n",
    "with sns.axes_style('white'):\n",
    "    plt.figure()\n",
    "    plt.imshow(china)\n",
    "    plt.title('input: 16 million colors')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(new_image)\n",
    "    plt.title('{0} colors'.format(n_colors))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
